{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理 Knowledge Dataset 的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file = \"dataset/knowledgeDataset.xlsx\"\n",
    "csv_file = \"dataset/knowledgeDataset.csv\"\n",
    "\n",
    "# Display the sheet names in the Excel file\n",
    "excel_sheets = pd.ExcelFile(excel_file, engine=\"openpyxl\").sheet_names\n",
    "print(f\"Excel 文件中的工作表: {excel_sheets}\")\n",
    "\n",
    "for sheet in excel_sheets:\n",
    "    print(f\"正在處理工作表: {sheet}\")\n",
    "    if sheet != \"Training wav\":\n",
    "        csv_file = f\"dataset/{sheet}.csv\"\n",
    "    else:\n",
    "        csv_file = f\"dataset/transcripts.csv\"\n",
    "    df = pd.read_excel(excel_file, engine=\"openpyxl\", sheet_name=sheet)\n",
    "    df.to_csv(csv_file, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Excel 轉換為 CSV 完成，存為 {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 處理 Training wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmyhealer/miniforge3/envs/careerhack/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "/home/jimmyhealer/miniforge3/envs/careerhack/lib/python3.13/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATASET_ADUIO_NAME = \"dataset/training.wav\"\n",
    "audio = AudioSegment.from_wav(DATASET_ADUIO_NAME)\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "diarization = pipeline(DATASET_ADUIO_NAME)\n",
    "\n",
    "times = []\n",
    "\n",
    "count = 1\n",
    "\n",
    "os.makedirs(\"tmp\", exist_ok=True)\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    start_ms = int(turn.start * 1000) \n",
    "    end_ms = int(turn.end * 1000)\n",
    "    segment = audio[start_ms:end_ms]\n",
    "    filename = f\"tmp/s_{count}_{speaker}_{start_ms}_{end_ms}.wav\"\n",
    "    count += 1\n",
    "    segment.export(filename, format=\"wav\")\n",
    "    times.append((speaker, start_ms, end_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合併後的時間序列：\n",
      "Speaker: Daisy, Start: 891 ms, End: 11877 ms, File: merged_audio/1_Daisy_891_11877.wav\n",
      "Speaker: Martin, Start: 13412 ms, End: 20854 ms, File: merged_audio/2_Martin_13412_20854.wav\n",
      "Speaker: Lisa, Start: 23369 ms, End: 37814 ms, File: merged_audio/3_Lisa_23369_37814.wav\n",
      "Speaker: Daisy, Start: 39788 ms, End: 48141 ms, File: merged_audio/4_Daisy_39788_48141.wav\n",
      "Speaker: Ivan, Start: 49626 ms, End: 51702 ms, File: merged_audio/5_Ivan_49626_51702.wav\n",
      "Speaker: Daisy, Start: 53187 ms, End: 64628 ms, File: merged_audio/6_Daisy_53187_64628.wav\n",
      "Speaker: Ivan, Start: 67294 ms, End: 80423 ms, File: merged_audio/7_Ivan_67294_80423.wav\n",
      "Speaker: Daisy, Start: 82245 ms, End: 91240 ms, File: merged_audio/8_Daisy_82245_91240.wav\n",
      "Speaker: Martin, Start: 92742 ms, End: 95847 ms, File: merged_audio/9_Martin_92742_95847.wav\n",
      "Speaker: Daisy, Start: 97214 ms, End: 99947 ms, File: merged_audio/10_Daisy_97214_99947.wav\n",
      "Speaker: Martin, Start: 100234 ms, End: 100605 ms, File: merged_audio/11_Martin_100234_100605.wav\n",
      "Speaker: Daisy, Start: 101483 ms, End: 102715 ms, File: merged_audio/12_Daisy_101483_102715.wav\n",
      "Speaker: SPEAKER01, Start: 103407 ms, End: 103964 ms, File: merged_audio/13_SPEAKER01_103407_103964.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "audio_dir = \"./tmp\"\n",
    "\n",
    "file_list = [f for f in os.listdir(audio_dir) if f.endswith(\".wav\")]\n",
    "file_list.sort(key=lambda x: int(x.split(\"_\")[1]))\n",
    "\n",
    "merged_segments = []\n",
    "current_speaker = None\n",
    "current_start = None\n",
    "current_end = None\n",
    "current_audio = None\n",
    "\n",
    "speaker_map = {\n",
    "    \"SPEAKER00\": \"Martin\",\n",
    "    \"SPEAKER01\": \"Ivan\",\n",
    "    \"SPEAKER02\": \"Daisy\",\n",
    "    \"SPEAKER03\": \"Lisa\",\n",
    "}\n",
    "\n",
    "for file_name in file_list:\n",
    "    _, _, speaker, idx, start_ms, end_ms = file_name.replace(\".wav\", \"\").split(\"_\")\n",
    "    speaker += idx\n",
    "    start_ms, end_ms = int(start_ms), int(end_ms)\n",
    "    \n",
    "    if speaker == current_speaker:\n",
    "        current_end = end_ms\n",
    "        segment = AudioSegment.from_file(os.path.join(audio_dir, file_name))\n",
    "        current_audio += segment\n",
    "    else:\n",
    "        if current_speaker is not None:\n",
    "            merged_segments.append({\n",
    "                \"speaker\": speaker_map[current_speaker],\n",
    "                \"start_ms\": current_start,\n",
    "                \"end_ms\": current_end,\n",
    "                \"audio\": current_audio\n",
    "            })\n",
    "        current_speaker = speaker\n",
    "        current_start = start_ms\n",
    "        current_end = end_ms\n",
    "        current_audio = AudioSegment.from_file(os.path.join(audio_dir, file_name))\n",
    "\n",
    "if current_speaker is not None:\n",
    "    merged_segments.append({\n",
    "        \"speaker\": current_speaker,\n",
    "        \"start_ms\": current_start,\n",
    "        \"end_ms\": current_end,\n",
    "        \"audio\": current_audio\n",
    "    })\n",
    "\n",
    "time_sequence = []\n",
    "output_dir = \"dataset/train_split_audio\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i, segment in enumerate(merged_segments, 1):\n",
    "    output_file = os.path.join(output_dir, f\"{i}_{segment['speaker']}_{segment['start_ms']}_{segment['end_ms']}.wav\")\n",
    "    segment[\"audio\"].export(output_file, format=\"wav\")\n",
    "    time_sequence.append({\n",
    "        \"speaker\": segment[\"speaker\"],\n",
    "        \"start\": segment[\"start_ms\"],\n",
    "        \"end\": segment[\"end_ms\"],\n",
    "        \"file\": output_file\n",
    "    })\n",
    "\n",
    "print(\"合併後的時間序列：\")\n",
    "for seq in time_sequence:\n",
    "    print(f\"Speaker: {seq['speaker']}, Start: {seq['start']} ms, End: {seq['end']} ms, File: {seq['file']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "careerhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
