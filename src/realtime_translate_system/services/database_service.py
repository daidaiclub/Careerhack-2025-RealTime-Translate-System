import psycopg2
import numpy as np
from vertexai.language_models import TextEmbeddingModel
import ast
from typing import List, Dict, Any
from realtime_translate_system.services.ai_service import  EmbeddingService

# PostgreSQL é€£ç·šè¨­å®š
DB_CONFIG = {
    "dbname": "meetings_db",
    "user": "postgres",
    "password": "postgres",
    "host": "127.0.0.1",  # Cloud SQL Proxy é€£ç·š
    "port": "5433"
}

class Document:
    def __init__(self, doc_id, title, created_at, update_time, content, embedding, keywords, similarity=None):
        self.id = doc_id
        self.title = title
        self.created_at = created_at
        self.update_time = update_time
        self.content = content
        self.embedding = embedding
        self.keywords = keywords
        self.similarity = similarity
    
    def __str__(self):
        return f"Document(id={self.id}, title={self.title}, created_at={self.created_at}, update_time={self.update_time}, content={self.content[:50]}..., keywords={self.keywords}, similarity={self.similarity}), embedding={self.embedding[:10]}..."


class DatabaseService:
    def __init__(self, embedding_service: EmbeddingService):
        """åˆå§‹åŒ–è³‡æ–™åº«é€£ç·š"""
        self.conn = psycopg2.connect(**DB_CONFIG)
        self.embedding_service = embedding_service
        self.cur = self.conn.cursor()
    
    def __del__(self):
        """ç‰©ä»¶è¢«éŠ·æ¯€æ™‚é—œé–‰é€£ç·š"""
        self.cur.close()
        self.conn.close()
    
    def get_text_embedding(self, text: str) -> np.ndarray:
        """ä½¿ç”¨ Google Vertex AI å–å¾—æ–‡æœ¬çš„åµŒå…¥å‘é‡ (768 ç¶­)"""
        return np.array(self.embedding_service.get_embedding(text))
    
    def get_meetings(self) -> List[Document]:
        """ç²å–æ‰€æœ‰æœƒè­°è¨˜éŒ„"""
        try:
            self.cur.execute("SELECT id, title, created_at, update_time, content, embedding, keywords FROM documents;")
            rows = self.cur.fetchall()
            return [Document(row[0], row[1], row[2], row[3], row[4], row[5], row[6]) for row in rows]
        except Exception as e:
            print(f"âŒ æŸ¥è©¢å¤±æ•—: {e}")
            return []

    def search_meetings(self, query_embedding: List[float], top_k: int = 5) -> List[Document]:
        """é€éé—œéµå­—æœå°‹æœƒè­°è¨˜éŒ„ï¼Œè¿”å› `top_k` ç­†çµæœï¼Œä¸¦åŒ…å«æ‰€æœ‰æ¬„ä½"""
        try:
            self.cur.execute("""
                SELECT id, title, created_at, update_time, content, embedding, keywords, embedding <=> %s::vector(768) AS similarity
                FROM documents
                ORDER BY similarity ASC
                LIMIT %s;
            """, (query_embedding, top_k))
            rows = self.cur.fetchall()
            return [Document(row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7]) for row in rows]
        except Exception as e:
            print(f"âŒ æŸ¥è©¢å¤±æ•—: {e}")
            return []

    def save_meeting(self, title: str, transcript: str, keywords: List[str]):
        """å„²å­˜æ–°çš„æœƒè­°è¨˜éŒ„ï¼Œcreated_at è‡ªå‹•è¨­å®š"""
        try:
            embedding_array = self.get_text_embedding(transcript)
            embedding_list = embedding_array.tolist()
            self.cur.execute("""
                INSERT INTO documents (title, content, embedding, keywords)
                VALUES (%s, %s, %s, %s);
            """, (title, transcript, embedding_list, keywords))
            self.conn.commit()
            print("âœ… æˆåŠŸå„²å­˜æœƒè­°è¨˜éŒ„ï¼")
        except Exception as e:
            print(f"âŒ å„²å­˜å¤±æ•—: {e}")

    def update_meeting(self, doc_id: int, title: str, transcript: str, keywords: List[str]):
        """æ›´æ–°æœƒè­°è¨˜éŒ„ï¼Œä¸¦è‡ªå‹•æ›´æ–° update_time"""
        try:
            embedding_array = self.get_text_embedding(transcript)
            embedding_list = embedding_array.tolist()
            self.cur.execute("""
                UPDATE documents
                SET title = %s, content = %s, embedding = %s, keywords = %s, update_time = NOW()
                WHERE id = %s;
            """, (title, transcript, embedding_list, keywords, doc_id))
            self.conn.commit()
            print("âœ… æˆåŠŸæ›´æ–°æœƒè­°è¨˜éŒ„ï¼")
        except Exception as e:
            print(f"âŒ æ›´æ–°å¤±æ•—: {e}")



if __name__ == "__main__":
    db_service = DatabaseService()
    
    # print("ğŸ”¹ æ¸¬è©¦ save_meeting")
    # db_service.save_meeting("æœƒè­°3", "æ¯å¤©å­¸ç¿’ä¸€é»æ–°çŸ¥è­˜ï¼Œé•·æœŸä¸‹ä¾†æœƒå¸¶ä¾†æ„æƒ³ä¸åˆ°çš„æ”¶ç©«ã€‚", ["AI", "ç§‘æŠ€"])
    
    # print("ğŸ”¹ æ¸¬è©¦ get_meetings")
    # meetings = db_service.get_meetings()
    # for meeting in meetings:
    #     print(meeting)
    
    # print("ğŸ”¹ æ¸¬è©¦ update_meeting")
    # db_service.update_meeting(1, "æ›´æ–°å¾Œçš„æœƒè­°1", "é€™æ˜¯æ›´æ–°å¾Œçš„å…§å®¹", ["AI", "æ•¸æ“š"])
    
    print("ğŸ”¹ æ¸¬è©¦ search_meetings")
    query_embedding = "å…¨çƒæš–åŒ–"
    query_embedding = db_service.get_text_embedding(query_embedding)
    results = db_service.search_meetings(query_embedding.tolist(), top_k=3)
    for result in results:
        print(result)
    




# æ¸¬è©¦æ’å…¥æ–‡æœ¬
# text_input = """DDR Ratioï¼ˆDouble Data Rate Ratioï¼‰ æ˜¯ç”¨ä¾†è¡¡é‡è¨˜æ†¶é«”ï¼ˆRAMï¼‰é‹ä½œæ•ˆç‡çš„ä¸€å€‹é—œéµæŒ‡æ¨™ï¼Œç‰¹åˆ¥æ˜¯åœ¨è¨ˆç®—æ©Ÿç³»çµ±å’ŒåµŒå…¥å¼è¨­å‚™ä¸­ã€‚DDR è¨˜æ†¶é«”æŠ€è¡“ï¼ˆå¦‚ DDR3ã€DDR4ã€DDR5ï¼‰é€šéé›™å€æ•¸æ“šé€Ÿç‡å‚³è¼¸ä¾†æé«˜å­˜å–æ•ˆç‡ï¼Œä½¿å¾—æ•¸æ“šåœ¨æ™‚è„ˆ ä¿¡è™Ÿçš„ä¸Šå‡èˆ‡ä¸‹é™æ²¿çš†å¯å‚³è¼¸ï¼Œæé«˜ç¸½é«”çš„è³‡æ–™ååé‡ã€‚

# DDR Ratio é€šå¸¸æŒ‡çš„æ˜¯è¨˜æ†¶é«”çš„æ™‚è„ˆé »ç‡ï¼ˆClock Speedï¼‰èˆ‡å¯¦éš›æ•¸æ“šå‚³è¼¸é€Ÿç‡ï¼ˆData Rateï¼‰ä¹‹é–“çš„æ¯”ç‡ã€‚ä¾‹å¦‚ï¼š

# åœ¨ DDR4-3200 è¨˜æ†¶é«”ä¸­ï¼Œæ™‚è„ˆé »ç‡ç‚º 1600 MHzï¼Œä½†ç”±æ–¼ DDR æŠ€è¡“æ¡ç”¨é›™å€æ•¸æ“šå‚³è¼¸ï¼Œå¯¦éš›çš„æ•¸æ“šé€Ÿç‡ç‚º 3200 MT/sï¼ˆMega Transfers per secondï¼‰ï¼Œå› æ­¤ DDR Ratio é€šå¸¸è¡¨ç¤ºç‚º 2:1ã€‚
# å°æ–¼ DDR5 è¨˜æ†¶é«”ï¼Œéš¨è‘—æŠ€è¡“é€²æ­¥ï¼Œæ•¸æ“šå‚³è¼¸æ•ˆç‡é€²ä¸€æ­¥æå‡ï¼Œä½†ä»ç„¶ä¿æŒç›¸ä¼¼çš„æ¯”ä¾‹é—œä¿‚ã€‚
# åœ¨æ•ˆèƒ½æ¸¬è©¦æˆ–è¶…é »èª¿æ ¡æ™‚ï¼ŒDDR Ratio å¯èƒ½å½±éŸ¿ç³»çµ±ç©©å®šæ€§èˆ‡é »å¯¬è¡¨ç¾ï¼Œå› æ­¤èª¿æ•´è¨˜æ†¶é«”åƒæ•¸æ™‚éœ€è¦è€ƒé‡æ­¤æ¯”ä¾‹ï¼Œä»¥ç¢ºä¿æœ€ä½³çš„é‹è¡Œæ•ˆèƒ½å’Œç©©å®šæ€§ã€‚"""
# insert_embedding(text_input)

#æŸ¥è©¢æ‰€æœ‰æ–‡æª”
# fetch_all_documents()

# # æŸ¥è©¢ç›¸ä¼¼æ–‡æª”
# query_text = """"""
# find_top_similar_documents(query_text, top_k=3)
