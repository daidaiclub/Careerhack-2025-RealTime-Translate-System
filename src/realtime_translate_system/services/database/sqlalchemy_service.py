import numpy as np
from typing import List
from realtime_translate_system.models.doc import Doc
from realtime_translate_system.models import db
from sqlalchemy import text, desc
from datetime import datetime
from database_service import DatabaseService

class SQLAlchemyDatabaseService(DatabaseService):
    def insert_document(
        self,
        title: str,
        transcript_chinese: str,
        transcript_english: str,
        transcript_german: str,
        transcript_japanese: str,
        keywords: list,
    ):
        """æ’å…¥æ–°çš„æœƒè­°è¨˜éŒ„"""
        try:
            embedding_array = self.get_text_embedding(transcript_chinese)
            embedding_list = (
                embedding_array.tolist()
            )  #  è½‰æ›ç‚º Python Listï¼Œæ‰èƒ½å­˜å…¥ SQLAlchemy

            # ğŸ”¹ **SQL æ’å…¥èªå¥**
            sql = text(
                """
                INSERT INTO documents (
                    title, transcript_chinese, transcript_english, 
                    transcript_german, transcript_japanese, embedding, keywords
                ) VALUES (
                    :title, :transcript_chinese, :transcript_english,
                    :transcript_german, :transcript_japanese, :embedding, :keywords
                ) RETURNING id;
            """
            )

            # ğŸ”¹ **åŸ·è¡Œ SQL æ’å…¥**
            result = db.session.execute(
                sql,
                {
                    "title": title,
                    # "created_at": datetime.now(),
                    # "updated_at": datetime.now(),
                    "transcript_chinese": transcript_chinese,
                    "transcript_english": transcript_english,
                    "transcript_german": transcript_german,
                    "transcript_japanese": transcript_japanese,
                    "embedding": embedding_list,
                    "keywords": keywords,
                },
            )

            db.session.commit()

            new_id = result.fetchone()[0]  # å–å¾—æ–°æ’å…¥çš„ ID
            return new_id  # è¿”å›æ’å…¥çš„å°è±¡ ID

        except Exception as e:
            print(f"âŒ æ’å…¥å¤±æ•—: {e}")
            db.session.rollback()
            return None

        except Exception as e:
            db.session.rollback()
            print(f"æ’å…¥å¤±æ•—: {e}")
            return None

    def get_document(self, doc_id: int) -> Doc:
        """ç²å– `documents` è¡¨ä¸­çš„ä¸€ç­†è³‡æ–™ï¼Œä¸¦è¿”å›å­—å…¸åŒ…å«å…§å®¹èˆ‡ `type()`"""
        try:
            document = db.session.query(Doc).filter_by(id=doc_id).first()

            if document:
                # meeting_data = {}
                # print("ğŸ“„ æœƒè­°è¨˜éŒ„å…§å®¹ï¼š")
                # for column in Doc.__table__.columns:
                #     value = getattr(meeting, column.name)
                #     meeting_data[column.name] = {"value": value, "type": type(value).__name__}
                #     print(f"{column.name}: {value} (type: {type(value).__name__})")
                return document
            else:
                print("æ²’æœ‰æ‰¾åˆ°ä»»ä½•æœƒè­°è¨˜éŒ„ã€‚")
                return None

        except Exception as e:
            db.session.rollback()
            print(f"âŒ æŸ¥è©¢å¤±æ•—: {e}")
            return None

    def get_documents(self) -> List[Doc]:
        """ç²å–æ‰€æœ‰æœƒè­°è¨˜éŒ„"""
        # try:
        #     self.cur.execute("SELECT id, title, created_at, updated_at, content, embedding, keywords FROM Docs;")
        #     rows = self.cur.fetchall()
        #     return [Doc(row[0], row[1], row[2], row[3], row[4], row[5], row[6]) for row in rows]
        # except Exception as e:
        #     print(f"æŸ¥è©¢å¤±æ•—: {e}")
        #     return []
        try:
            return Doc.query.order_by(desc(Doc.updated_at)).all()
        except Exception as e:
            print(f"æŸ¥è©¢å¤±æ•—: {e}")
            return []


    def search_documents(
        self, query_embedding: List[float], top_k: int = 5
    ) -> List[Doc]:
        """é€éé—œéµå­—æœå°‹æœƒè­°è¨˜éŒ„ï¼Œè¿”å› `top_k` ç­†çµæœï¼Œä¸¦åŒ…å«æ‰€æœ‰æ¬„ä½"""
        # try:
        #     self.cur.execute("""
        #         SELECT id, title, created_at, updated_at, content, embedding, keywords, embedding <=> %s::vector(768) AS similarity
        #         FROM Docs
        #         ORDER BY similarity ASC
        #         LIMIT %s;
        #     """, (query_embedding, top_k))
        #     rows = self.cur.fetchall()
        #     return [Doc(row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7]) for row in rows]
        # except Exception as e:
        #     print(f"æŸ¥è©¢å¤±æ•—: {e}")
        #     return []
        # ğŸ”¹ ä¿®æ­£ SQL æŸ¥è©¢ï¼Œç§»é™¤ `content` ä¸¦ç¢ºä¿ `similarity` æ’åº
        try:
            sql = text(
                """
                SELECT id, title, created_at, updated_at, transcript_chinese, transcript_english, 
                        transcript_german, transcript_japanese, embedding, keywords
                FROM documents
                ORDER BY embedding <=> (:query_embedding)::vector(768) ASC
                LIMIT :top_k;
            """
            )

            # ğŸ”¹ åŸ·è¡ŒæŸ¥è©¢
            result = (
                db.session.execute(
                    sql, {"query_embedding": query_embedding, "top_k": top_k}
                )
                .mappings()
                .all()
            )

            # #  æª¢æŸ¥æ˜¯å¦æœ‰çµæœ
            # if not result:
            #     print("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆçš„æœƒè­°è¨˜éŒ„")
            #     return []

            # #  è¼¸å‡ºæ¯ä¸€ç­†æŸ¥è©¢çµæœ
            # print("ğŸ“Œ æœƒè­°è¨˜éŒ„æŸ¥è©¢çµæœï¼š")
            # for i, row in enumerate(result):
            #     print(f"\nğŸ”¹ æœƒè­° {i + 1}:")
            #     for key, value in row.items():
            #         print(f"  {key}: {value} (type: {type(value).__name__})")

            return [Doc(**row) for row in result]

        except Exception as e:
            print(f"âŒ æŸ¥è©¢å¤±æ•—: {e}")
            db.session.rollback()
            return []

    def update_document(
        self,
        doc_id: int,
        title: str,
        transcript_chinese: str,
        transcript_english: str,
        transcript_german: str,
        transcript_japanese: str,
        keywords: list,
    ):
        """æ›´æ–°æœƒè­°è¨˜éŒ„ï¼Œä¸¦è‡ªå‹•æ›´æ–° updated_at"""
        try:
            doc = db.session.query(Doc).filter_by(id=doc_id).first()

            if not doc:
                print(f"æ›´æ–°å¤±æ•— æ‰¾ä¸åˆ° ID {doc_id} çš„è¨˜éŒ„")
                return False

            doc.title = title
            doc.transcript_chinese = transcript_chinese
            doc.transcript_english = transcript_english
            doc.transcript_german = transcript_german
            doc.transcript_japanese = transcript_japanese
            doc.keywords = keywords
            doc.embedding = self.get_text_embedding(transcript_chinese).tolist()
            doc.updated_at = datetime.now()

            db.session.commit()
            print(f"æˆåŠŸæ›´æ–° ID {doc_id} çš„æœƒè­°è¨˜éŒ„")
            return True

        except Exception as e:
            db.session.rollback()
            print(f"æ›´æ–°å¤±æ•— {e}")
            return False


if __name__ == "__main__":
    from realtime_translate_system.services.embedding import VertexEmbeddingService
    embedding_service = VertexEmbeddingService("text-multilingual-embedding-002")
    db_service = DatabaseService(embedding_service=embedding_service)

    db_service.insert_document(
        title="AI ç™¼å±•è¶¨å‹¢",
        transcript_chinese="äººå·¥æ™ºèƒ½æ­£åœ¨å¿«é€Ÿç™¼å±•ï¼Œå°å„è¡Œå„æ¥­ç”¢ç”Ÿæ·±é å½±éŸ¿ã€‚",
        transcript_english="Artificial intelligence is rapidly evolving and has a profound impact on various industries.",
        transcript_german="KÃ¼nstliche Intelligenz entwickelt sich rasant und hat tiefgreifende Auswirkungen auf verschiedene Branchen.",
        transcript_japanese="äººå·¥çŸ¥èƒ½ã¯æ€¥é€Ÿã«é€²åŒ–ã—ã¦ãŠã‚Šã€ã•ã¾ã–ã¾ãªæ¥­ç•Œã«æ·±ã„å½±éŸ¿ã‚’ä¸ãˆã¦ã„ã¾ã™ã€‚",
        keywords=["AI", "Machine Learning", "ç§‘æŠ€"],
    )


# æ¸¬è©¦æ’å…¥æ–‡æœ¬
# text_input = """DDR Ratioï¼ˆDouble Data Rate Ratioï¼‰ æ˜¯ç”¨ä¾†è¡¡é‡è¨˜æ†¶é«”ï¼ˆRAMï¼‰é‹ä½œæ•ˆç‡çš„ä¸€å€‹é—œéµæŒ‡æ¨™ï¼Œç‰¹åˆ¥æ˜¯åœ¨è¨ˆç®—æ©Ÿç³»çµ±å’ŒåµŒå…¥å¼è¨­å‚™ä¸­ã€‚DDR è¨˜æ†¶é«”æŠ€è¡“ï¼ˆå¦‚ DDR3ã€DDR4ã€DDR5ï¼‰é€šéé›™å€æ•¸æ“šé€Ÿç‡å‚³è¼¸ä¾†æé«˜å­˜å–æ•ˆç‡ï¼Œä½¿å¾—æ•¸æ“šåœ¨æ™‚è„ˆ ä¿¡è™Ÿçš„ä¸Šå‡èˆ‡ä¸‹é™æ²¿çš†å¯å‚³è¼¸ï¼Œæé«˜ç¸½é«”çš„è³‡æ–™ååé‡ã€‚

# DDR Ratio é€šå¸¸æŒ‡çš„æ˜¯è¨˜æ†¶é«”çš„æ™‚è„ˆé »ç‡ï¼ˆClock Speedï¼‰èˆ‡å¯¦éš›æ•¸æ“šå‚³è¼¸é€Ÿç‡ï¼ˆData Rateï¼‰ä¹‹é–“çš„æ¯”ç‡ã€‚ä¾‹å¦‚ï¼š

# åœ¨ DDR4-3200 è¨˜æ†¶é«”ä¸­ï¼Œæ™‚è„ˆé »ç‡ç‚º 1600 MHzï¼Œä½†ç”±æ–¼ DDR æŠ€è¡“æ¡ç”¨é›™å€æ•¸æ“šå‚³è¼¸ï¼Œå¯¦éš›çš„æ•¸æ“šé€Ÿç‡ç‚º 3200 MT/sï¼ˆMega Transfers per secondï¼‰ï¼Œå› æ­¤ DDR Ratio é€šå¸¸è¡¨ç¤ºç‚º 2:1ã€‚
# å°æ–¼ DDR5 è¨˜æ†¶é«”ï¼Œéš¨è‘—æŠ€è¡“é€²æ­¥ï¼Œæ•¸æ“šå‚³è¼¸æ•ˆç‡é€²ä¸€æ­¥æå‡ï¼Œä½†ä»ç„¶ä¿æŒç›¸ä¼¼çš„æ¯”ä¾‹é—œä¿‚ã€‚
# åœ¨æ•ˆèƒ½æ¸¬è©¦æˆ–è¶…é »èª¿æ ¡æ™‚ï¼ŒDDR Ratio å¯èƒ½å½±éŸ¿ç³»çµ±ç©©å®šæ€§èˆ‡é »å¯¬è¡¨ç¾ï¼Œå› æ­¤èª¿æ•´è¨˜æ†¶é«”åƒæ•¸æ™‚éœ€è¦è€ƒé‡æ­¤æ¯”ä¾‹ï¼Œä»¥ç¢ºä¿æœ€ä½³çš„é‹è¡Œæ•ˆèƒ½å’Œç©©å®šæ€§ã€‚"""
# insert_embedding(text_input)

# æŸ¥è©¢æ‰€æœ‰æ–‡æª”
# fetch_all_Docs()

# # æŸ¥è©¢ç›¸ä¼¼æ–‡æª”
# query_text = """"""
# find_top_similar_Docs(query_text, top_k=3)
